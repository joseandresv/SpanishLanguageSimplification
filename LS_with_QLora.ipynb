{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1u0Q_C2aQxtn0T6ExiPOMnKoVELA0onmc",
      "authorship_tag": "ABX9TyMsOyXKTESk1XzsU41EDkZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2dbebf522da54c9a882108105280ef88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89b0adaa265a4dca978a0d50136123f0",
              "IPY_MODEL_dab3ae0f582e4da69fe8d843051e59e9",
              "IPY_MODEL_ed34016fbe04417092a797a7ef28c5d5",
              "IPY_MODEL_b2691a2697a049e0ba1c4d94fe6d73f2"
            ],
            "layout": "IPY_MODEL_6cb8203da89845a099b46dadb67166a0"
          }
        },
        "4c29d85f8a7548799e7bbcc67c439393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0d6b77a6944a24b3d747039777a48b",
            "placeholder": "​",
            "style": "IPY_MODEL_8568a5dbbaf84c599e94733d2585c1f5",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "255e9d97d84349f4ad4b46e3e84c3f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_849719624bfb4704bd58673d8ab215e2",
            "placeholder": "​",
            "style": "IPY_MODEL_efd667e52a474597985f6c4f4ca165be",
            "value": ""
          }
        },
        "7cdcfe8a253948e5aba0cfd303f34390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a0aab2e773a8498fb9bb1e1563af8c80",
            "style": "IPY_MODEL_a82f3be51c39474daeb988b60100e970",
            "value": true
          }
        },
        "efb5d897848a4362baa3ed3e686b5687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3a0882a587e14b3f96599a914ac52e02",
            "style": "IPY_MODEL_14db779e9b1f405082225ba205096948",
            "tooltip": ""
          }
        },
        "15e341e927b04629a3a76b4389ed4e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fcea0a4f8a844b4970a4f9995103398",
            "placeholder": "​",
            "style": "IPY_MODEL_54bb9ff491484028bd6b5d3e57f1833e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "6cb8203da89845a099b46dadb67166a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "da0d6b77a6944a24b3d747039777a48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8568a5dbbaf84c599e94733d2585c1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849719624bfb4704bd58673d8ab215e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd667e52a474597985f6c4f4ca165be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0aab2e773a8498fb9bb1e1563af8c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a82f3be51c39474daeb988b60100e970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a0882a587e14b3f96599a914ac52e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14db779e9b1f405082225ba205096948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3fcea0a4f8a844b4970a4f9995103398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54bb9ff491484028bd6b5d3e57f1833e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fef6d5e7c93b4860a32f5cbfb9cf73b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32cdce77909c4e00bd1742f9f448253d",
            "placeholder": "​",
            "style": "IPY_MODEL_ff361a89078149f88631f16d4ed2a822",
            "value": "Connecting..."
          }
        },
        "32cdce77909c4e00bd1742f9f448253d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff361a89078149f88631f16d4ed2a822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89b0adaa265a4dca978a0d50136123f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b38a979918e49c1adb24dd4b7a31caa",
            "placeholder": "​",
            "style": "IPY_MODEL_2c71ffde97b84af4ae176c3c987760fb",
            "value": "Token is valid (permission: read)."
          }
        },
        "dab3ae0f582e4da69fe8d843051e59e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a31603ba8b546938c630181bd59f8d0",
            "placeholder": "​",
            "style": "IPY_MODEL_5bc6ee7f6e014b4ca4259b83ea0bc410",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "ed34016fbe04417092a797a7ef28c5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59168a7dcb1a4315b7996bdcb692a1ec",
            "placeholder": "​",
            "style": "IPY_MODEL_8af15e6174bd42f593d4fbcfcb6623c2",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "b2691a2697a049e0ba1c4d94fe6d73f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2954f96e0d3c4a7b9593f25ef6b3a1dc",
            "placeholder": "​",
            "style": "IPY_MODEL_6e7671e5819142d796e09e7b0fc4c8e8",
            "value": "Login successful"
          }
        },
        "4b38a979918e49c1adb24dd4b7a31caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c71ffde97b84af4ae176c3c987760fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a31603ba8b546938c630181bd59f8d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bc6ee7f6e014b4ca4259b83ea0bc410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59168a7dcb1a4315b7996bdcb692a1ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af15e6174bd42f593d4fbcfcb6623c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2954f96e0d3c4a7b9593f25ef6b3a1dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7671e5819142d796e09e7b0fc4c8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e8faade5de456190d8bbd58d8e19cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_043b2c33a08247afaaf5227ef3ffc1a6",
              "IPY_MODEL_1dec24b1e1ea4c7c85aba79238889a04",
              "IPY_MODEL_f2d5597d170e48e2856e85af3a095be2"
            ],
            "layout": "IPY_MODEL_fbfe10d135424e3bba4e1b27a79309b0"
          }
        },
        "043b2c33a08247afaaf5227ef3ffc1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f30f4be4cc458dba457f1fa2b0a5d9",
            "placeholder": "​",
            "style": "IPY_MODEL_20c27f0d57464298b6a313b0e6c7fc4d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1dec24b1e1ea4c7c85aba79238889a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7453a64e538c404b9349f6312327402c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98deaf9e272d4de89d443450b1ab5e62",
            "value": 2
          }
        },
        "f2d5597d170e48e2856e85af3a095be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f34f1fec89a418182b0e0e9f002da5f",
            "placeholder": "​",
            "style": "IPY_MODEL_f5d26bbe9d064a44aa211a77ab2cb7d8",
            "value": " 2/2 [00:04&lt;00:00,  2.27s/it]"
          }
        },
        "fbfe10d135424e3bba4e1b27a79309b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6f30f4be4cc458dba457f1fa2b0a5d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c27f0d57464298b6a313b0e6c7fc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7453a64e538c404b9349f6312327402c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98deaf9e272d4de89d443450b1ab5e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f34f1fec89a418182b0e0e9f002da5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d26bbe9d064a44aa211a77ab2cb7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4736b02c874f7c856c234bbe2bdb6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69864fcf386c49ad8950d44b30511980",
              "IPY_MODEL_ad0e199375be444eb2d96b19c19af7fd",
              "IPY_MODEL_a56175eff01a419a94a1421a202c77f6"
            ],
            "layout": "IPY_MODEL_e2267bfba8ca45b0bf570474bba95118"
          }
        },
        "69864fcf386c49ad8950d44b30511980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fa6921eb50e47e4b29fe8e9eb762108",
            "placeholder": "​",
            "style": "IPY_MODEL_63765008b1bd4afeb5838689292f6d7a",
            "value": "Map: 100%"
          }
        },
        "ad0e199375be444eb2d96b19c19af7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04620b261b014b94bfc16f63948a854a",
            "max": 7894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dda7f677c6b146d29ad9d26f395bb2ec",
            "value": 7894
          }
        },
        "a56175eff01a419a94a1421a202c77f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fd097743c8437583bb400a6049c00c",
            "placeholder": "​",
            "style": "IPY_MODEL_333b8357120c43aca0e599f8a2048c7c",
            "value": " 7894/7894 [00:00&lt;00:00, 12729.07 examples/s]"
          }
        },
        "e2267bfba8ca45b0bf570474bba95118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa6921eb50e47e4b29fe8e9eb762108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63765008b1bd4afeb5838689292f6d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04620b261b014b94bfc16f63948a854a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda7f677c6b146d29ad9d26f395bb2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2fd097743c8437583bb400a6049c00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "333b8357120c43aca0e599f8a2048c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseandresv/SpanishLanguageSimplification/blob/main/LS_with_QLora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning of LLM for Causal Generation from Lexical Complexity Dataset"
      ],
      "metadata": {
        "id": "Gpkh7xIEx4vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "input: texto complejo\n",
        "\n",
        "transforms:\n",
        "* lexico T5, BERT\n",
        "* sintactico\n",
        "* estilo GPT3, LLama2\n",
        "* discurso GPT3, LLama2\n",
        "\n",
        "output: texto menos complejo\n",
        "\n",
        "al final tenemos pares input buenos input malos\n"
      ],
      "metadata": {
        "id": "KBdSo129aRUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Libraries and Logins"
      ],
      "metadata": {
        "id": "Ac15u4q4yMXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZgv40nv2cj3",
        "outputId": "a5bb858f-16ff-4524-edd3-d64e290315f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd4y5XvlPNty",
        "outputId": "968504a4-2263-4b1d-df75-1a543d77746e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trl\n",
            "  Downloading trl-0.8.4-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.40.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.30.0.dev0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.18.0)\n",
            "Collecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.8.3-py3-none-any.whl (102 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.2)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
            "Installing collected packages: shtab, tyro, trl\n",
            "Successfully installed shtab-1.7.1 trl-0.8.4 tyro-0.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "2dbebf522da54c9a882108105280ef88",
            "4c29d85f8a7548799e7bbcc67c439393",
            "255e9d97d84349f4ad4b46e3e84c3f49",
            "7cdcfe8a253948e5aba0cfd303f34390",
            "efb5d897848a4362baa3ed3e686b5687",
            "15e341e927b04629a3a76b4389ed4e28",
            "6cb8203da89845a099b46dadb67166a0",
            "da0d6b77a6944a24b3d747039777a48b",
            "8568a5dbbaf84c599e94733d2585c1f5",
            "849719624bfb4704bd58673d8ab215e2",
            "efd667e52a474597985f6c4f4ca165be",
            "a0aab2e773a8498fb9bb1e1563af8c80",
            "a82f3be51c39474daeb988b60100e970",
            "3a0882a587e14b3f96599a914ac52e02",
            "14db779e9b1f405082225ba205096948",
            "3fcea0a4f8a844b4970a4f9995103398",
            "54bb9ff491484028bd6b5d3e57f1833e",
            "fef6d5e7c93b4860a32f5cbfb9cf73b3",
            "32cdce77909c4e00bd1742f9f448253d",
            "ff361a89078149f88631f16d4ed2a822",
            "89b0adaa265a4dca978a0d50136123f0",
            "dab3ae0f582e4da69fe8d843051e59e9",
            "ed34016fbe04417092a797a7ef28c5d5",
            "b2691a2697a049e0ba1c4d94fe6d73f2",
            "4b38a979918e49c1adb24dd4b7a31caa",
            "2c71ffde97b84af4ae176c3c987760fb",
            "4a31603ba8b546938c630181bd59f8d0",
            "5bc6ee7f6e014b4ca4259b83ea0bc410",
            "59168a7dcb1a4315b7996bdcb692a1ec",
            "8af15e6174bd42f593d4fbcfcb6623c2",
            "2954f96e0d3c4a7b9593f25ef6b3a1dc",
            "6e7671e5819142d796e09e7b0fc4c8e8"
          ]
        },
        "id": "z0qJ1JSl_kla",
        "outputId": "2f7db9c3-5cc7-4a80-8b1b-3375efb7f09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dbebf522da54c9a882108105280ef88"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Calling and Parameter Setting"
      ],
      "metadata": {
        "id": "s6yIswf0ybk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify model_id for different models from huggingface"
      ],
      "metadata": {
        "id": "dVt0pd3SzdbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
        "\n",
        "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\" : 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "83e8faade5de456190d8bbd58d8e19cf",
            "043b2c33a08247afaaf5227ef3ffc1a6",
            "1dec24b1e1ea4c7c85aba79238889a04",
            "f2d5597d170e48e2856e85af3a095be2",
            "fbfe10d135424e3bba4e1b27a79309b0",
            "b6f30f4be4cc458dba457f1fa2b0a5d9",
            "20c27f0d57464298b6a313b0e6c7fc4d",
            "7453a64e538c404b9349f6312327402c",
            "98deaf9e272d4de89d443450b1ab5e62",
            "2f34f1fec89a418182b0e0e9f002da5f",
            "f5d26bbe9d064a44aa211a77ab2cb7d8"
          ]
        },
        "id": "2AuIC-WB24hY",
        "outputId": "e38f5a70-7632-4845-be40-f204609e137c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e8faade5de456190d8bbd58d8e19cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "1mmfDXmF42ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "  \"\"\"prints the number of trainable parameters in the model\"\"\"\n",
        "  trainable_params = 0\n",
        "  all_param = 0\n",
        "  for _, param in model.named_parameters():\n",
        "    all_param += param.numel()\n",
        "    if param.requires_grad:\n",
        "      trainable_params += param.numel()\n",
        "  print(\n",
        "      f\"trainable params: {trainable_params} \\\\ all params: {all_param} trainable%: {100 * trainable_params / all_param}\"\n",
        "  )"
      ],
      "metadata": {
        "id": "taNvvzjR41n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config =  LoraConfig(\n",
        "    r=64,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL\",\n",
        "    inference_mode=False\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KefJYFQJHybq",
        "outputId": "016b1104-dc20-47da-8f7f-610f6f4bd8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 33554432 \\ all params: 3533967360 trainable%: 0.9494833591219133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict().keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ohGA6emJEd7",
        "outputId": "6ac5afac-6a10-4232-d2c4-78221e585e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.weight', 'base_model.model.model.layers.0.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.0.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.0.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.0.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.0.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.weight', 'base_model.model.model.layers.0.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.0.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.0.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.0.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.0.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.0.mlp.gate_proj.weight', 'base_model.model.model.layers.0.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.0.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.0.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.0.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.0.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.0.mlp.up_proj.weight', 'base_model.model.model.layers.0.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.0.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.0.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.0.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.0.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.0.mlp.down_proj.weight', 'base_model.model.model.layers.0.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.0.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.0.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.0.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.0.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.weight', 'base_model.model.model.layers.1.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.1.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.1.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.1.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.1.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.weight', 'base_model.model.model.layers.1.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.1.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.1.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.1.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.1.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.1.mlp.gate_proj.weight', 'base_model.model.model.layers.1.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.1.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.1.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.1.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.1.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.1.mlp.up_proj.weight', 'base_model.model.model.layers.1.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.1.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.1.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.1.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.1.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.1.mlp.down_proj.weight', 'base_model.model.model.layers.1.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.1.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.1.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.1.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.1.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.weight', 'base_model.model.model.layers.2.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.2.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.2.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.2.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.2.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.weight', 'base_model.model.model.layers.2.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.2.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.2.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.2.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.2.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.2.mlp.gate_proj.weight', 'base_model.model.model.layers.2.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.2.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.2.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.2.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.2.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.2.mlp.up_proj.weight', 'base_model.model.model.layers.2.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.2.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.2.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.2.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.2.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.2.mlp.down_proj.weight', 'base_model.model.model.layers.2.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.2.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.2.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.2.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.2.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.weight', 'base_model.model.model.layers.3.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.3.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.3.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.3.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.3.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.weight', 'base_model.model.model.layers.3.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.3.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.3.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.3.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.3.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.3.mlp.gate_proj.weight', 'base_model.model.model.layers.3.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.3.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.3.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.3.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.3.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.3.mlp.up_proj.weight', 'base_model.model.model.layers.3.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.3.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.3.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.3.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.3.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.3.mlp.down_proj.weight', 'base_model.model.model.layers.3.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.3.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.3.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.3.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.3.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.weight', 'base_model.model.model.layers.4.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.4.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.4.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.4.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.4.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.weight', 'base_model.model.model.layers.4.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.4.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.4.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.4.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.4.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.4.mlp.gate_proj.weight', 'base_model.model.model.layers.4.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.4.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.4.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.4.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.4.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.4.mlp.up_proj.weight', 'base_model.model.model.layers.4.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.4.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.4.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.4.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.4.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.4.mlp.down_proj.weight', 'base_model.model.model.layers.4.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.4.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.4.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.4.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.4.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.weight', 'base_model.model.model.layers.5.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.5.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.5.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.5.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.5.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.weight', 'base_model.model.model.layers.5.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.5.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.5.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.5.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.5.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.5.mlp.gate_proj.weight', 'base_model.model.model.layers.5.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.5.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.5.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.5.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.5.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.5.mlp.up_proj.weight', 'base_model.model.model.layers.5.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.5.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.5.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.5.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.5.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.5.mlp.down_proj.weight', 'base_model.model.model.layers.5.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.5.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.5.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.5.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.5.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.weight', 'base_model.model.model.layers.6.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.6.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.6.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.6.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.6.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.weight', 'base_model.model.model.layers.6.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.6.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.6.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.6.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.6.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.6.mlp.gate_proj.weight', 'base_model.model.model.layers.6.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.6.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.6.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.6.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.6.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.6.mlp.up_proj.weight', 'base_model.model.model.layers.6.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.6.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.6.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.6.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.6.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.6.mlp.down_proj.weight', 'base_model.model.model.layers.6.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.6.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.6.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.6.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.6.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.weight', 'base_model.model.model.layers.7.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.7.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.7.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.7.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.7.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.weight', 'base_model.model.model.layers.7.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.7.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.7.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.7.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.7.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.7.mlp.gate_proj.weight', 'base_model.model.model.layers.7.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.7.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.7.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.7.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.7.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.7.mlp.up_proj.weight', 'base_model.model.model.layers.7.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.7.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.7.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.7.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.7.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.7.mlp.down_proj.weight', 'base_model.model.model.layers.7.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.7.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.7.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.7.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.7.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.weight', 'base_model.model.model.layers.8.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.8.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.8.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.8.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.8.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.weight', 'base_model.model.model.layers.8.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.8.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.8.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.8.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.8.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.8.mlp.gate_proj.weight', 'base_model.model.model.layers.8.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.8.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.8.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.8.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.8.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.8.mlp.up_proj.weight', 'base_model.model.model.layers.8.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.8.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.8.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.8.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.8.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.8.mlp.down_proj.weight', 'base_model.model.model.layers.8.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.8.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.8.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.8.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.8.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.weight', 'base_model.model.model.layers.9.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.9.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.9.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.9.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.9.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.weight', 'base_model.model.model.layers.9.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.9.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.9.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.9.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.9.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.9.mlp.gate_proj.weight', 'base_model.model.model.layers.9.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.9.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.9.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.9.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.9.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.9.mlp.up_proj.weight', 'base_model.model.model.layers.9.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.9.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.9.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.9.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.9.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.9.mlp.down_proj.weight', 'base_model.model.model.layers.9.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.9.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.9.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.9.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.9.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.weight', 'base_model.model.model.layers.10.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.10.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.10.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.10.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.10.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.weight', 'base_model.model.model.layers.10.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.10.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.10.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.10.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.10.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.10.mlp.gate_proj.weight', 'base_model.model.model.layers.10.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.10.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.10.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.10.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.10.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.10.mlp.up_proj.weight', 'base_model.model.model.layers.10.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.10.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.10.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.10.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.10.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.10.mlp.down_proj.weight', 'base_model.model.model.layers.10.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.10.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.10.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.10.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.10.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.weight', 'base_model.model.model.layers.11.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.11.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.11.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.11.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.11.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.weight', 'base_model.model.model.layers.11.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.11.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.11.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.11.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.11.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.11.mlp.gate_proj.weight', 'base_model.model.model.layers.11.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.11.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.11.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.11.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.11.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.11.mlp.up_proj.weight', 'base_model.model.model.layers.11.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.11.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.11.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.11.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.11.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.11.mlp.down_proj.weight', 'base_model.model.model.layers.11.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.11.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.11.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.11.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.11.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.weight', 'base_model.model.model.layers.12.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.12.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.12.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.12.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.12.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.weight', 'base_model.model.model.layers.12.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.12.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.12.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.12.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.12.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.12.mlp.gate_proj.weight', 'base_model.model.model.layers.12.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.12.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.12.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.12.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.12.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.12.mlp.up_proj.weight', 'base_model.model.model.layers.12.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.12.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.12.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.12.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.12.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.12.mlp.down_proj.weight', 'base_model.model.model.layers.12.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.12.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.12.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.12.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.12.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.weight', 'base_model.model.model.layers.13.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.13.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.13.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.13.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.13.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.weight', 'base_model.model.model.layers.13.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.13.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.13.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.13.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.13.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.13.mlp.gate_proj.weight', 'base_model.model.model.layers.13.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.13.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.13.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.13.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.13.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.13.mlp.up_proj.weight', 'base_model.model.model.layers.13.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.13.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.13.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.13.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.13.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.13.mlp.down_proj.weight', 'base_model.model.model.layers.13.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.13.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.13.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.13.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.13.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.weight', 'base_model.model.model.layers.14.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.14.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.14.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.14.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.14.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.weight', 'base_model.model.model.layers.14.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.14.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.14.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.14.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.14.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.14.mlp.gate_proj.weight', 'base_model.model.model.layers.14.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.14.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.14.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.14.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.14.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.14.mlp.up_proj.weight', 'base_model.model.model.layers.14.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.14.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.14.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.14.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.14.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.14.mlp.down_proj.weight', 'base_model.model.model.layers.14.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.14.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.14.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.14.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.14.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.weight', 'base_model.model.model.layers.15.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.15.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.15.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.15.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.15.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.weight', 'base_model.model.model.layers.15.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.15.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.15.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.15.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.15.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.15.mlp.gate_proj.weight', 'base_model.model.model.layers.15.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.15.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.15.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.15.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.15.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.15.mlp.up_proj.weight', 'base_model.model.model.layers.15.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.15.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.15.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.15.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.15.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.15.mlp.down_proj.weight', 'base_model.model.model.layers.15.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.15.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.15.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.15.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.15.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.weight', 'base_model.model.model.layers.16.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.16.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.16.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.16.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.16.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.weight', 'base_model.model.model.layers.16.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.16.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.16.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.16.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.16.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.16.mlp.gate_proj.weight', 'base_model.model.model.layers.16.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.16.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.16.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.16.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.16.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.16.mlp.up_proj.weight', 'base_model.model.model.layers.16.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.16.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.16.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.16.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.16.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.16.mlp.down_proj.weight', 'base_model.model.model.layers.16.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.16.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.16.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.16.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.16.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.weight', 'base_model.model.model.layers.17.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.17.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.17.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.17.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.17.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.weight', 'base_model.model.model.layers.17.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.17.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.17.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.17.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.17.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.17.mlp.gate_proj.weight', 'base_model.model.model.layers.17.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.17.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.17.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.17.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.17.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.17.mlp.up_proj.weight', 'base_model.model.model.layers.17.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.17.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.17.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.17.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.17.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.17.mlp.down_proj.weight', 'base_model.model.model.layers.17.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.17.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.17.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.17.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.17.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.weight', 'base_model.model.model.layers.18.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.18.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.18.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.18.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.18.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.weight', 'base_model.model.model.layers.18.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.18.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.18.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.18.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.18.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.18.mlp.gate_proj.weight', 'base_model.model.model.layers.18.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.18.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.18.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.18.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.18.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.18.mlp.up_proj.weight', 'base_model.model.model.layers.18.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.18.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.18.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.18.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.18.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.18.mlp.down_proj.weight', 'base_model.model.model.layers.18.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.18.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.18.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.18.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.18.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.weight', 'base_model.model.model.layers.19.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.19.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.19.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.19.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.19.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.weight', 'base_model.model.model.layers.19.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.19.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.19.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.19.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.19.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.19.mlp.gate_proj.weight', 'base_model.model.model.layers.19.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.19.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.19.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.19.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.19.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.19.mlp.up_proj.weight', 'base_model.model.model.layers.19.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.19.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.19.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.19.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.19.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.19.mlp.down_proj.weight', 'base_model.model.model.layers.19.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.19.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.19.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.19.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.19.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.weight', 'base_model.model.model.layers.20.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.20.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.20.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.20.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.20.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.weight', 'base_model.model.model.layers.20.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.20.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.20.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.20.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.20.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.20.mlp.gate_proj.weight', 'base_model.model.model.layers.20.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.20.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.20.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.20.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.20.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.20.mlp.up_proj.weight', 'base_model.model.model.layers.20.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.20.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.20.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.20.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.20.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.20.mlp.down_proj.weight', 'base_model.model.model.layers.20.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.20.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.20.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.20.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.20.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.weight', 'base_model.model.model.layers.21.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.21.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.21.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.21.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.21.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.weight', 'base_model.model.model.layers.21.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.21.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.21.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.21.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.21.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.21.mlp.gate_proj.weight', 'base_model.model.model.layers.21.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.21.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.21.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.21.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.21.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.21.mlp.up_proj.weight', 'base_model.model.model.layers.21.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.21.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.21.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.21.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.21.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.21.mlp.down_proj.weight', 'base_model.model.model.layers.21.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.21.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.21.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.21.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.21.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.weight', 'base_model.model.model.layers.22.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.22.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.22.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.22.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.22.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.weight', 'base_model.model.model.layers.22.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.22.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.22.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.22.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.22.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.22.mlp.gate_proj.weight', 'base_model.model.model.layers.22.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.22.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.22.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.22.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.22.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.22.mlp.up_proj.weight', 'base_model.model.model.layers.22.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.22.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.22.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.22.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.22.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.22.mlp.down_proj.weight', 'base_model.model.model.layers.22.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.22.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.22.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.22.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.22.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.weight', 'base_model.model.model.layers.23.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.23.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.23.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.23.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.23.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.weight', 'base_model.model.model.layers.23.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.23.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.23.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.23.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.23.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.23.mlp.gate_proj.weight', 'base_model.model.model.layers.23.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.23.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.23.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.23.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.23.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.23.mlp.up_proj.weight', 'base_model.model.model.layers.23.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.23.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.23.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.23.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.23.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.23.mlp.down_proj.weight', 'base_model.model.model.layers.23.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.23.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.23.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.23.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.23.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.weight', 'base_model.model.model.layers.24.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.24.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.24.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.24.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.24.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.weight', 'base_model.model.model.layers.24.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.24.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.24.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.24.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.24.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.24.mlp.gate_proj.weight', 'base_model.model.model.layers.24.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.24.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.24.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.24.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.24.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.24.mlp.up_proj.weight', 'base_model.model.model.layers.24.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.24.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.24.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.24.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.24.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.24.mlp.down_proj.weight', 'base_model.model.model.layers.24.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.24.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.24.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.24.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.24.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.weight', 'base_model.model.model.layers.25.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.25.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.25.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.25.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.25.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.weight', 'base_model.model.model.layers.25.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.25.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.25.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.25.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.25.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.25.mlp.gate_proj.weight', 'base_model.model.model.layers.25.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.25.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.25.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.25.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.25.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.25.mlp.up_proj.weight', 'base_model.model.model.layers.25.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.25.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.25.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.25.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.25.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.25.mlp.down_proj.weight', 'base_model.model.model.layers.25.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.25.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.25.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.25.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.25.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.weight', 'base_model.model.model.layers.26.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.26.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.26.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.26.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.26.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.weight', 'base_model.model.model.layers.26.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.26.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.26.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.26.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.26.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.26.mlp.gate_proj.weight', 'base_model.model.model.layers.26.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.26.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.26.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.26.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.26.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.26.mlp.up_proj.weight', 'base_model.model.model.layers.26.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.26.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.26.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.26.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.26.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.26.mlp.down_proj.weight', 'base_model.model.model.layers.26.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.26.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.26.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.26.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.26.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.weight', 'base_model.model.model.layers.27.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.27.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.27.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.27.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.27.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.weight', 'base_model.model.model.layers.27.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.27.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.27.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.27.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.27.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.27.mlp.gate_proj.weight', 'base_model.model.model.layers.27.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.27.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.27.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.27.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.27.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.27.mlp.up_proj.weight', 'base_model.model.model.layers.27.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.27.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.27.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.27.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.27.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.27.mlp.down_proj.weight', 'base_model.model.model.layers.27.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.27.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.27.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.27.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.27.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.weight', 'base_model.model.model.layers.28.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.28.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.28.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.28.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.28.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.weight', 'base_model.model.model.layers.28.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.28.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.28.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.28.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.28.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.28.mlp.gate_proj.weight', 'base_model.model.model.layers.28.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.28.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.28.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.28.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.28.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.28.mlp.up_proj.weight', 'base_model.model.model.layers.28.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.28.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.28.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.28.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.28.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.28.mlp.down_proj.weight', 'base_model.model.model.layers.28.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.28.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.28.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.28.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.28.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.weight', 'base_model.model.model.layers.29.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.29.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.29.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.29.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.29.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.weight', 'base_model.model.model.layers.29.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.29.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.29.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.29.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.29.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.29.mlp.gate_proj.weight', 'base_model.model.model.layers.29.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.29.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.29.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.29.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.29.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.29.mlp.up_proj.weight', 'base_model.model.model.layers.29.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.29.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.29.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.29.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.29.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.29.mlp.down_proj.weight', 'base_model.model.model.layers.29.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.29.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.29.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.29.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.29.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.weight', 'base_model.model.model.layers.30.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.30.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.30.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.30.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.30.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.weight', 'base_model.model.model.layers.30.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.30.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.30.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.30.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.30.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.30.mlp.gate_proj.weight', 'base_model.model.model.layers.30.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.30.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.30.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.30.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.30.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.30.mlp.up_proj.weight', 'base_model.model.model.layers.30.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.30.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.30.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.30.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.30.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.30.mlp.down_proj.weight', 'base_model.model.model.layers.30.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.30.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.30.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.30.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.30.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.weight', 'base_model.model.model.layers.31.self_attn.k_proj.weight.absmax', 'base_model.model.model.layers.31.self_attn.k_proj.weight.quant_map', 'base_model.model.model.layers.31.self_attn.k_proj.weight.nested_absmax', 'base_model.model.model.layers.31.self_attn.k_proj.weight.nested_quant_map', 'base_model.model.model.layers.31.self_attn.k_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.nested_absmax', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.nested_quant_map', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.weight', 'base_model.model.model.layers.31.self_attn.o_proj.weight.absmax', 'base_model.model.model.layers.31.self_attn.o_proj.weight.quant_map', 'base_model.model.model.layers.31.self_attn.o_proj.weight.nested_absmax', 'base_model.model.model.layers.31.self_attn.o_proj.weight.nested_quant_map', 'base_model.model.model.layers.31.self_attn.o_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.31.mlp.gate_proj.weight', 'base_model.model.model.layers.31.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.31.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.31.mlp.gate_proj.weight.nested_absmax', 'base_model.model.model.layers.31.mlp.gate_proj.weight.nested_quant_map', 'base_model.model.model.layers.31.mlp.gate_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.31.mlp.up_proj.weight', 'base_model.model.model.layers.31.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.31.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.31.mlp.up_proj.weight.nested_absmax', 'base_model.model.model.layers.31.mlp.up_proj.weight.nested_quant_map', 'base_model.model.model.layers.31.mlp.up_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.31.mlp.down_proj.weight', 'base_model.model.model.layers.31.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.31.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.31.mlp.down_proj.weight.nested_absmax', 'base_model.model.model.layers.31.mlp.down_proj.weight.nested_quant_map', 'base_model.model.model.layers.31.mlp.down_proj.weight.quant_state.bitsandbytes__nf4', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.model.norm.weight', 'base_model.model.lm_head.weight'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lexical Complexity Data Transformation"
      ],
      "metadata": {
        "id": "O_8Ba-70yhTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_GWdu1jJAFE",
        "outputId": "ea382793-8de6-43bc-bf75-42f00c67e154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/MCC/Tesis/SGSS_sentence_pairs.csv\", sep=';')\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pH-yP500H7Ev",
        "outputId": "ef41ae4e-a382-4fc6-96ae-697d9eccf39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  La importancia de leer bien el etiquetado ante...   \n",
              "1  La importancia de leer bien el etiquetado ante...   \n",
              "2  La importancia de leer bien el etiquetado ante...   \n",
              "3  El Ministerio de Sanidad, Consumo y Bienestar ...   \n",
              "4  El Ministerio de Sanidad, Consumo y Bienestar ...   \n",
              "\n",
              "                                        new_sentence  \n",
              "0  La importancia de leer bien el letrero antes d...  \n",
              "1  La importancia de leer bien el  inscripción an...  \n",
              "2  La importancia de leer bien el  rótulo antes d...  \n",
              "3  El Ministerio de Sanidad, Consumo y Bienestar ...  \n",
              "4  El Ministerio de Sanidad, Consumo y Bienestar ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79a0aa9c-a65d-4141-bb00-ed4e61bfebcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>new_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La importancia de leer bien el etiquetado ante...</td>\n",
              "      <td>La importancia de leer bien el letrero antes d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La importancia de leer bien el etiquetado ante...</td>\n",
              "      <td>La importancia de leer bien el  inscripción an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La importancia de leer bien el etiquetado ante...</td>\n",
              "      <td>La importancia de leer bien el  rótulo antes d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79a0aa9c-a65d-4141-bb00-ed4e61bfebcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79a0aa9c-a65d-4141-bb00-ed4e61bfebcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79a0aa9c-a65d-4141-bb00-ed4e61bfebcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-72f77e2f-cd58-4fbf-900a-9bf7389cd2f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72f77e2f-cd58-4fbf-900a-9bf7389cd2f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-72f77e2f-cd58-4fbf-900a-9bf7389cd2f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7894,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3015,\n        \"samples\": [\n          \"Gracias a las nuevas tecnolog\\u00edas resulta m\\u00e1s f\\u00e1cil mantener el contacto con las personas que a uno le importan\",\n          \"\\u201cLas personas mayores y con enfermedades cr\\u00f3nicas son las m\\u00e1s vulnerables ante la pandemia, tanto por su vulnerabilidad ante la Covid-19, como por las consecuencias de la misma y el d\\u00e9ficit de la atenci\\u00f3n sanitaria\",\n          \"En este punto, la ministra ha instado a la UE a impulsar y propiciar el consenso en varios temas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7848,\n        \"samples\": [\n          \"Con \\u201cLa sombra del cardenal\\u201d abandono moment\\u00e1neamente mi vinculaci\\u00f3n con el mundo antiguo y medieval, para llevar al lector a algunos de los momentos m\\u00e1s  inquietantes de la Europa del Renacimiento, situando la escena en la Italia de mediados del siglo XVI, dos a\\u00f1os despu\\u00e9s de clausurarse el Concilio de Trento, con una trama que sorprende porque desnudo las debilidades de un complejo mundo lleno de intrigas, pasiones, rebeliones, asesinatos y crudeza, donde la Inquisici\\u00f3n adquiri\\u00f3 un poder casi\",\n          \"Incorpora una modificaci\\u00f3n en los procedimientos de  expulsi\\u00f3n, por la que se establece de forma obligatoria la participaci\\u00f3n de los Servicios Sociales en dichos procesos\",\n          \"Esto se me hizo especialmente claro cuando falleci\\u00f3 mi madre hace unos a\\u00f1os\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNnergC-Jnen",
        "outputId": "7cd8d765-9d16-4e2b-d17c-2f8bf88edc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7894, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"formatted_instruction\"] = df.apply(lambda x: f\"### Instruction:\\n{x['sentence']}\\n\\n### Response:\\n{x['new_sentence']}\", axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GHflMhj4ISFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5532cb62-18ac-49c2-d901-fc7de2a11862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  La importancia de leer bien el etiquetado ante...   \n",
              "1  La importancia de leer bien el etiquetado ante...   \n",
              "2  La importancia de leer bien el etiquetado ante...   \n",
              "3  El Ministerio de Sanidad, Consumo y Bienestar ...   \n",
              "4  El Ministerio de Sanidad, Consumo y Bienestar ...   \n",
              "\n",
              "                                        new_sentence  \\\n",
              "0  La importancia de leer bien el letrero antes d...   \n",
              "1  La importancia de leer bien el  inscripción an...   \n",
              "2  La importancia de leer bien el  rótulo antes d...   \n",
              "3  El Ministerio de Sanidad, Consumo y Bienestar ...   \n",
              "4  El Ministerio de Sanidad, Consumo y Bienestar ...   \n",
              "\n",
              "                               formatted_instruction  \n",
              "0  ### Instruction:\\nLa importancia de leer bien ...  \n",
              "1  ### Instruction:\\nLa importancia de leer bien ...  \n",
              "2  ### Instruction:\\nLa importancia de leer bien ...  \n",
              "3  ### Instruction:\\nEl Ministerio de Sanidad, Co...  \n",
              "4  ### Instruction:\\nEl Ministerio de Sanidad, Co...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89b48be5-04a9-491c-a756-7e8f6e240205\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>new_sentence</th>\n",
              "      <th>formatted_instruction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La importancia de leer bien el etiquetado ante...</td>\n",
              "      <td>La importancia de leer bien el letrero antes d...</td>\n",
              "      <td>### Instruction:\\nLa importancia de leer bien ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La importancia de leer bien el etiquetado ante...</td>\n",
              "      <td>La importancia de leer bien el  inscripción an...</td>\n",
              "      <td>### Instruction:\\nLa importancia de leer bien ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La importancia de leer bien el etiquetado ante...</td>\n",
              "      <td>La importancia de leer bien el  rótulo antes d...</td>\n",
              "      <td>### Instruction:\\nLa importancia de leer bien ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "      <td>### Instruction:\\nEl Ministerio de Sanidad, Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "      <td>El Ministerio de Sanidad, Consumo y Bienestar ...</td>\n",
              "      <td>### Instruction:\\nEl Ministerio de Sanidad, Co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89b48be5-04a9-491c-a756-7e8f6e240205')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89b48be5-04a9-491c-a756-7e8f6e240205 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89b48be5-04a9-491c-a756-7e8f6e240205');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-efa0d6fb-2d00-458a-ad44-d5150e09a868\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-efa0d6fb-2d00-458a-ad44-d5150e09a868')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-efa0d6fb-2d00-458a-ad44-d5150e09a868 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7894,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3015,\n        \"samples\": [\n          \"Gracias a las nuevas tecnolog\\u00edas resulta m\\u00e1s f\\u00e1cil mantener el contacto con las personas que a uno le importan\",\n          \"\\u201cLas personas mayores y con enfermedades cr\\u00f3nicas son las m\\u00e1s vulnerables ante la pandemia, tanto por su vulnerabilidad ante la Covid-19, como por las consecuencias de la misma y el d\\u00e9ficit de la atenci\\u00f3n sanitaria\",\n          \"En este punto, la ministra ha instado a la UE a impulsar y propiciar el consenso en varios temas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7848,\n        \"samples\": [\n          \"Con \\u201cLa sombra del cardenal\\u201d abandono moment\\u00e1neamente mi vinculaci\\u00f3n con el mundo antiguo y medieval, para llevar al lector a algunos de los momentos m\\u00e1s  inquietantes de la Europa del Renacimiento, situando la escena en la Italia de mediados del siglo XVI, dos a\\u00f1os despu\\u00e9s de clausurarse el Concilio de Trento, con una trama que sorprende porque desnudo las debilidades de un complejo mundo lleno de intrigas, pasiones, rebeliones, asesinatos y crudeza, donde la Inquisici\\u00f3n adquiri\\u00f3 un poder casi\",\n          \"Incorpora una modificaci\\u00f3n en los procedimientos de  expulsi\\u00f3n, por la que se establece de forma obligatoria la participaci\\u00f3n de los Servicios Sociales en dichos procesos\",\n          \"Esto se me hizo especialmente claro cuando falleci\\u00f3 mi madre hace unos a\\u00f1os\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"formatted_instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7848,\n        \"samples\": [\n          \"### Instruction:\\nCon \\u201cLa sombra del cardenal\\u201d abandono moment\\u00e1neamente mi vinculaci\\u00f3n con el mundo antiguo y medieval, para llevar al lector a algunos de los momentos m\\u00e1s sobrecogedores de la Europa del Renacimiento, situando la escena en la Italia de mediados del siglo XVI, dos a\\u00f1os despu\\u00e9s de clausurarse el Concilio de Trento, con una trama que sorprende porque desnudo las debilidades de un complejo mundo lleno de intrigas, pasiones, rebeliones, asesinatos y crudeza, donde la Inquisici\\u00f3n adquiri\\u00f3 un poder casi\\n\\n### Response:\\nCon \\u201cLa sombra del cardenal\\u201d abandono moment\\u00e1neamente mi vinculaci\\u00f3n con el mundo antiguo y medieval, para llevar al lector a algunos de los momentos m\\u00e1s  inquietantes de la Europa del Renacimiento, situando la escena en la Italia de mediados del siglo XVI, dos a\\u00f1os despu\\u00e9s de clausurarse el Concilio de Trento, con una trama que sorprende porque desnudo las debilidades de un complejo mundo lleno de intrigas, pasiones, rebeliones, asesinatos y crudeza, donde la Inquisici\\u00f3n adquiri\\u00f3 un poder casi\",\n          \"### Instruction:\\nIncorpora una modificaci\\u00f3n en los procedimientos de desahucio, por la que se establece de forma obligatoria la participaci\\u00f3n de los Servicios Sociales en dichos procesos\\n\\n### Response:\\nIncorpora una modificaci\\u00f3n en los procedimientos de  expulsi\\u00f3n, por la que se establece de forma obligatoria la participaci\\u00f3n de los Servicios Sociales en dichos procesos\",\n          \"### Instruction:\\nEsto se me hizo especialmente evidente cuando falleci\\u00f3 mi madre hace unos a\\u00f1os\\n\\n### Response:\\nEsto se me hizo especialmente claro cuando falleci\\u00f3 mi madre hace unos a\\u00f1os\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)"
      ],
      "metadata": {
        "id": "QZHWBPicG26n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"formatted_instruction_tok_len\"] = df[\"formatted_instruction\"].apply(lambda x:len(tokenizer.encode(x)))\n"
      ],
      "metadata": {
        "id": "a3-FwArhI-x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.boxplot(x=df[\"formatted_instruction_tok_len\"])\n",
        "\n",
        "plt.xlabel(\"formatted_instruction_tok_len\")\n",
        "plt.title(\"token length\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "3FjcV9YyJCgE",
        "outputId": "2ee8c994-3617-4fa2-e9f0-c2030f26cbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Approcimate maximum token lenght for a paragraph from Clear Language Rules\n",
        "context_lenght = 25*8*3\n",
        "print(context_lenght)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvSRmKc3Kfwo",
        "outputId": "535c4d12-8358-46a1-e4fb-6768d47cb636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llama 2 models offer a context length of 4,096 tokens\n",
        "\n",
        "https://llama.meta.com/faq/"
      ],
      "metadata": {
        "id": "qk2z3INrSp6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, load_dataset\n",
        "import datasets\n",
        "\n",
        "data = datasets.Dataset.from_pandas(df)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sLbfEokXofN",
        "outputId": "776edc8a-4d76-4f32-f89b-221fbb3db3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['sentence', 'new_sentence', 'formatted_instruction', 'formatted_instruction_tok_len'],\n",
            "    num_rows: 7894\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=100)\n",
        "prompt = \"### Instruction:\\nEl carro anda turulato, hay que llevarlo al mecánico.\\n\\n### Response:\\n\"\n",
        "gen_text = pipe(prompt)\n",
        "print(gen_text[0]['generated_text'][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abTq6S_IMQMe",
        "outputId": "79e43566-da89-471e-9874-e7f4c92e0850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The car is running in circles, it has to be taken to the mechanic.\n",
            "\n",
            "### Examples:\n",
            "\n",
            "- El carro anda turulato, hay que llevarlo al mecánico.\n",
            "- The car is running in circles, it has to be taken to the mechanic.\n",
            "\n",
            "##\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "QSjYue57NB6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## for llama"
      ],
      "metadata": {
        "id": "OqaMCxTmYiFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_params = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "pUwaX8ClOHDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params = TrainingArguments(\n",
        "    output_dir=\"./\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=50,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"tensorboard\"\n",
        ")"
      ],
      "metadata": {
        "id": "I2KP5rBHOEvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/trl/sft_trainer\n",
        "\n",
        "https://github.com/huggingface/trl/blob/main/trl/trainer/sft_trainer.py"
      ],
      "metadata": {
        "id": "2rAucvRhSgwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "tG9qHmCVOOCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=data,\n",
        "    peft_config=peft_params,\n",
        "    dataset_text_field=\"formatted_instruction\",\n",
        "    max_seq_length=128,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_params,\n",
        "    packing=False,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "F4MUwTYmC4_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8b4736b02c874f7c856c234bbe2bdb6e",
            "69864fcf386c49ad8950d44b30511980",
            "ad0e199375be444eb2d96b19c19af7fd",
            "a56175eff01a419a94a1421a202c77f6",
            "e2267bfba8ca45b0bf570474bba95118",
            "0fa6921eb50e47e4b29fe8e9eb762108",
            "63765008b1bd4afeb5838689292f6d7a",
            "04620b261b014b94bfc16f63948a854a",
            "dda7f677c6b146d29ad9d26f395bb2ec",
            "d2fd097743c8437583bb400a6049c00c",
            "333b8357120c43aca0e599f8a2048c7c"
          ]
        },
        "outputId": "313ac7f0-b22f-4c67-a975-7e5003c7bad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7894 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b4736b02c874f7c856c234bbe2bdb6e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x9HDvdRVO0zc",
        "outputId": "f16ec37d-1acd-442e-c19b-8f6bed5cf950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3947' max='3947' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3947/3947 25:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.756000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.306900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.356000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.494100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.112100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.435700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.061600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.327500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.329100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.136600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>1.413100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.373100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.056200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>1.330400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.093400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>1.292600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.132600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>1.310700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.058800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>1.367600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.043700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>1.181800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.034200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>1.172300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.126700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>1.266100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>1.323100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.080300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>1.284100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.998700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>1.248800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.093600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>1.294200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.027700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>1.224100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.068900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>1.195100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>1.212300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>1.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>1.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>1.146700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.031000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>1.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>1.018800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>1.150100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>1.217300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>1.084800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>1.156400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.033100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>1.203800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>1.069400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>1.171500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.019900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>1.149700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.978600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>1.162200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.029200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>1.080300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.966800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>1.102100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>1.140600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.945700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>1.207100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.034700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>1.202300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>1.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>1.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.896500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>1.020500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.967000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>1.011300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.937900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>1.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>1.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>1.053600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>1.106800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.960100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>0.980800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.962100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>0.933100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.955800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>1.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.964400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>1.013700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.994900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>0.938600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.955700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>0.996100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.939200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.944900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.943400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>0.914900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2575</td>\n",
              "      <td>1.035700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.934800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2625</td>\n",
              "      <td>1.054100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.977300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2675</td>\n",
              "      <td>1.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.915600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2725</td>\n",
              "      <td>1.113300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.961200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2775</td>\n",
              "      <td>0.940500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.894400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2825</td>\n",
              "      <td>0.931400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.937900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2875</td>\n",
              "      <td>0.943600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>1.021800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2925</td>\n",
              "      <td>0.974400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.996600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2975</td>\n",
              "      <td>0.951500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.837800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3025</td>\n",
              "      <td>0.920200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3075</td>\n",
              "      <td>0.958400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.839800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3125</td>\n",
              "      <td>0.939900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.912100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3175</td>\n",
              "      <td>0.933100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.846900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3225</td>\n",
              "      <td>0.818800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.839200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3275</td>\n",
              "      <td>0.964700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.849600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3325</td>\n",
              "      <td>0.906200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.872100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3375</td>\n",
              "      <td>0.804200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.896800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3425</td>\n",
              "      <td>0.906800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.825100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3475</td>\n",
              "      <td>0.847300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.864900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3525</td>\n",
              "      <td>0.792800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.828800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3575</td>\n",
              "      <td>0.986100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.871700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3625</td>\n",
              "      <td>0.825400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.860900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3675</td>\n",
              "      <td>0.866700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.878700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3725</td>\n",
              "      <td>0.898200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.830300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3775</td>\n",
              "      <td>0.879700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.841500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3825</td>\n",
              "      <td>0.913500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.811300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3875</td>\n",
              "      <td>0.872700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.902600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3925</td>\n",
              "      <td>0.815300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3947, training_loss=1.0393563640972376, metrics={'train_runtime': 1524.7664, 'train_samples_per_second': 5.177, 'train_steps_per_second': 2.589, 'total_flos': 3.516658341366989e+16, 'train_loss': 1.0393563640972376, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=300)\n",
        "prompt = \"###Instruction:En la placida tarde, las hojas danzan con gracia bajo la suave caricia del viento, mientras el sol se desliza lentamente hacia el horizonte, tiñendo el cielo de tonos cálidos y dorados.\\n\\n\\n###Response\\n:\"\n",
        "gen_text = pipe(prompt)\n",
        "print(gen_text[0]['generated_text'][len(prompt):])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT4G9IenP7hu",
        "outputId": "b6cde9d0-26b5-47cf-8e62-f00738cfd2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En la  pacífica tarde, las hojas danzan con gracia bajo la suave caricia del viento, mientras el sol se desliza lentamente hacia el horizonte, tiñendo el cielo de tonos cálidos y dorados.\n",
            "\n",
            "\n",
            "###Response:En la  tranquila tarde, las hojas danzan con gracia bajo la suave caricia del viento, mientras el sol se desliza lentamente hacia el horizonte, tiñendo el cielo de tonos cálidos y dorados.\n",
            "\n",
            "\n",
            "###Response:En la   pacífica tarde, las hojas danzan con gracia bajo la suave caricia del viento, mientras el sol se desliza lentamente hacia el horizonte, tiñendo el cielo de tonos cálidos y dorados.\n",
            "\n",
            "\n",
            "###Response:En la  tranquila tarde, las hojas danzan con gracia bajo la suave car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Experiments\n",
        "*   Train vs Test (Data Part)\n",
        "*   Distancia coseno\n"
      ],
      "metadata": {
        "id": "dIF-HhQebw4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## for T5"
      ],
      "metadata": {
        "id": "vuj-RV6lYmo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "8WW_xwLRXHvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(data[\"sentence\"], return_tensors=\"pt\").input_ids\n",
        "labels = tokenizer(data[\"new_sentece\"], return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "s7hIdEitXZnM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}